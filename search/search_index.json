{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>This is a very simple utility script that I just created so that you could send the content of a pdf to an LLM and talk to it.</p>"},{"location":"#instructions","title":"instructions","text":"<p>To install the app, you just need to do,</p> <pre><code>pip install talk-to-a-file\n\n# or\n\npip install git+https://github.com/deven367/talk-to-a-file\n</code></pre> <p>If you wish to develop/contribute to the project,</p> <pre><code>git clone https://github.com/deven367/talk-to-a-file\ncd talk-to-a-file\npip install -e .\n</code></pre>"},{"location":"#prerequisites","title":"prerequisites","text":"<p>To use this package, you need to use your own <code>ANTHROPIC_API_KEY</code>. Before using the CLI command, you need to set the environment variable. To do so,</p> <pre><code>export ANTHROPIC_API_KEY=&lt;your-api-key&gt;\n</code></pre>"},{"location":"#how-it-works","title":"how it works","text":"<p>Once the package is installed, you can use the CLI command, <code>talk-to-a-file</code>,</p> <p>The CLI has a required argument, <code>pdf</code>, which is the path to the pdf file that you want to read.</p> <p></p> <p>Here is a small example, where I talk to the pdf file, <code>docs/tcm.pdf</code>,</p> <p></p> <p>To quit the CLI, you can type <code>exit</code> or <code>quit</code>.</p>"},{"location":"#how-to-contribute","title":"how to contribute","text":"<p>Issues and PRs are welcome. If you have any suggestions or improvements, feel free to open an issue or a PR.</p>"},{"location":"api/talk/","title":"talk","text":""},{"location":"api/talk/#ttf.talk.chat_with_file","title":"<code>chat_with_file(path, prompt)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>description</p> required <code>prompt</code> <code>str</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p> Source code in <code>ttf/talk.py</code> <pre><code>def chat_with_file(path: str, prompt:str) -&gt; str:\n    \"\"\"_summary_\n\n    Args:\n        path (str): _description_\n        prompt (str): _description_\n\n    Returns:\n        str: _description_\n    \"\"\"\n\n    if path.endswith('.pdf'):\n        reader = PdfReader(path)\n        text = \"\\n\".join([page.extract_text() for page in reader.pages])\n\n    elif path.endswith('.txt'):\n        text = open(path, 'r').read()\n    else:\n        extension = path.split('.')[-1]\n        raise ValueError(f'Files ending in \"{extension}\" are not yet supported')\n\n    user_input = prompt + \":\\n\\n\" + text\n    chat_with(user_input)\n</code></pre>"},{"location":"api/utils/","title":"utils","text":""},{"location":"api/utils/#ttf.utils.chat_with","title":"<code>chat_with(user_input)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>user_input</code> <code>str</code> <p>description</p> required Source code in <code>ttf/utils.py</code> <pre><code>def chat_with(user_input:str)-&gt; None:\n    \"\"\"_summary_\n\n    Args:\n        user_input (str): _description_\n    \"\"\"\n    # Initialize the conversation history with a message from the chatbot\n    # message_log = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n    message_log = []\n\n    # Set a flag to keep track of whether this is the first request in the conversation\n    first_request = True\n\n    console = Console()\n\n    # Start a loop that runs until the user types \"quit\"\n    while True:\n        if first_request:\n            # If this is the first request, get the user's input and add it to the conversation history\n            # user_input = input(\"You: \")\n            # user_input = Prompt.ask(\"You   \")\n            message_log.append(\n                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_input}]}\n            )\n\n            # Send the conversation history to the chatbot and get its response\n            response = send_message(message_log)\n\n            # Add the chatbot's response to the conversation history and print it to the console\n            message_log.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": response}]})\n            # print(f\"AI assistant: {response}\")\n\n            console.print(Markdown(f\"Haiku : {response}\\n\\n---\"))\n            # Set the flag to False so that this branch is not executed again\n            first_request = False\n        else:\n            # If this is not the first request, get the user's input and add it to the conversation history\n            # user_input = input(\"You: \")\n            user_input = Prompt.ask(\"You   \")\n\n            # If the user types \"quit\", end the loop and print a goodbye message\n            if user_input.lower() == \"quit\" or user_input.lower() == \"exit\":\n                # print(\"Goodbye!\")\n                console.print(\"Goodbye!\")\n                break\n\n            message_log.append(\n                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_input}]}\n            )\n\n            # Send the conversation history to the chatbot and get its response\n            response = send_message(message_log)\n\n            # Add the chatbot's response to the conversation history and print it to the console\n            message_log.append({\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": response}]})\n            # print(f\"AI assistant: {response}\")\n            console.print(Markdown(f\"Haiku : {response}\\n\\n---\"))\n</code></pre>"},{"location":"api/utils/#ttf.utils.send_message","title":"<code>send_message(message_log)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>message_log</code> <code>list</code> <p>description</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>description</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p> Source code in <code>ttf/utils.py</code> <pre><code>def send_message(message_log: list) -&gt; str:\n    \"\"\"_summary_\n\n    Args:\n        message_log (list): _description_\n\n    Raises:\n        ValueError: _description_\n\n    Returns:\n        str: _description_\n    \"\"\"\n    try:\n        api_key = os.environ[\"ANTHROPIC_API_KEY\"]\n    except KeyError:\n        raise ValueError(\"ANTHROPIC_API_KEY not found in environment variables\")\n\n    client = anthropic.Client(api_key=api_key)\n\n    response = client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=3800,\n        system=\"Respond like a no non-sense assistant who answers to the point without any bullshit\",\n        messages=message_log,\n    )\n    return response.content[0].text\n</code></pre>"},{"location":"api/utils/#ttf.utils.summarize_pdf_old","title":"<code>summarize_pdf_old(client, path, prompt)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Client</code> <p>description</p> required <code>path</code> <code>str</code> <p>description</p> required <code>prompt</code> <code>str</code> <p>description</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>description</p> Source code in <code>ttf/utils.py</code> <pre><code>def summarize_pdf_old(client: anthropic.Client, path: str, prompt:str) -&gt; str:\n    \"\"\"_summary_\n\n    Args:\n        client (anthropic.Client): _description_\n        path (str): _description_\n        prompt (str): _description_\n\n    Returns:\n        str: _description_\n    \"\"\"\n    reader = PdfReader(path)\n    text = \"\\n\".join([page.extract_text() for page in reader.pages])\n\n    message_log = []\n    message_log.append(\n                {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": prompt + \":\\n\\n\" + text}]}\n            )\n\n    # prompt = f\"{anthropic.HUMAN_PROMPT}: Summarize the following text, should be readable:\\n\\n{text}\\n\\n{anthropic.AI_PROMPT}:\\n\\nSummary\"\n\n    response = client.messages.create(\n        model=\"claude-3-haiku-20240307\",\n        max_tokens=3800,\n        system=\"Respond like a no non-sense assistant who answers to the point without any bullshit\",\n        messages=message_log,\n    )\n\n    return response.content[0].text\n</code></pre>"}]}